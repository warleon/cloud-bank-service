# MS5 - Analytics y Data Lake# MS5 - DataLake con AWS S3, Glue y Athena (ACTUALIZADO PARA EC2)



## ğŸ“‹ DescripciÃ³nArquitectura completa de DataLake desplegada en **EC2 Ubuntu 22.04** con ingesta de datos desde mÃºltiples fuentes, catalogaciÃ³n con Glue y consultas analÃ­ticas vÃ­a API REST.



Microservicio de analytics que consulta datos del Data Lake en AWS S3 usando AWS Athena. Proporciona dashboards ejecutivos, reportes de cuentas, anÃ¡lisis de transacciones y mÃ©tricas de clientes a partir de datos histÃ³ricos almacenados en formato Parquet.## ğŸ—ï¸ Arquitectura



## ğŸ¯ PropÃ³sito```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

- Proporcionar analytics y KPIs para ejecutivos del bancoâ”‚                      EC2 Ubuntu 22.04                       â”‚

- Consultar grandes volÃºmenes de datos histÃ³ricos eficientementeâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚

- Generar reportes agregados desde el Data Lakeâ”‚  â”‚  Docker Containers (7 servicios)                     â”‚   â”‚

- Servir dashboards con mÃ©tricas de negocioâ”‚  â”‚  â”œâ”€ MySQL 8.0         (puerto 3307)                  â”‚   â”‚

â”‚  â”‚  â”œâ”€ PostgreSQL 15     (puerto 5433)                  â”‚   â”‚

## ğŸ—ï¸ Arquitecturaâ”‚  â”‚  â”œâ”€ MongoDB 7.0       (puerto 27018)                 â”‚   â”‚

â”‚  â”‚  â”œâ”€ Ingester MySQL    (ingesta01-mysql)              â”‚   â”‚

```mermaidâ”‚  â”‚  â”œâ”€ Ingester PostgreSQL (ingesta02-postgresql)       â”‚   â”‚

graph TBâ”‚  â”‚  â”œâ”€ Ingester MongoDB  (ingesta03-mongodb)            â”‚   â”‚

    subgraph "MS5 - Analytics"â”‚  â”‚  â””â”€ API REST FastAPI  (puerto 8000)                  â”‚   â”‚

        API[FastAPI Application]â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚

        AC[Athena Client]â”‚                           â”‚                                  â”‚

        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        API --> AC                            â”‚

    end                            â†“ boto3 (JSON Lines)

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

    Client[Dashboard/BI Tool] -->|HTTP REST| API        â”‚         Amazon S3 (3 Buckets)        â”‚

            â”‚  â”œâ”€ raw-ms1-data-bgc (MySQL)         â”‚

    AC -->|SQL Queries| Athena[AWS Athena]        â”‚  â”œâ”€ raw-ms2-data-bgc (PostgreSQL)    â”‚

    Athena -->|Query Results| AC        â”‚  â””â”€ raw-ms3-data-bgc (MongoDB)       â”‚

            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Athena -->|Scans Data| S3[(AWS S3 Data Lake)]                       â”‚

                           â†“ AWS Glue Crawlers

    subgraph "Data Lake Structure"        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

        S3 --> Clientes[/clientes/*.parquet/]        â”‚   AWS Glue Data Catalog (9 tablas)   â”‚

        S3 --> Cuentas[/cuentas/*.parquet/]        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        S3 --> Transacciones[/transacciones/*.parquet/]                       â”‚

    end                       â†“ Athena SQL Queries

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

    DI[Data Ingester] -->|ETL Process| S3        â”‚      Amazon Athena (Query Engine)    â”‚

            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    style API fill:#3498db,color:#fff                       â”‚

    style Athena fill:#ff9900,color:#fff                       â†“ API REST (15+ endpoints)

    style S3 fill:#ff9900,color:#fff        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

```        â”‚      Usuarios/Aplicaciones           â”‚

        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸ› ï¸ TecnologÃ­as```



| Componente | TecnologÃ­a | VersiÃ³n |## ğŸ“ Estructura del Proyecto

|------------|------------|---------|

| **Lenguaje** | Python | 3.11 |```

| **Framework** | FastAPI | 0.104.1 |cloud-m5/

| **Cliente Athena** | boto3 | 1.34+ |â”‚

| **Formato Data Lake** | Apache Parquet | - |â”œâ”€â”€ docker-compose.yml         # Orquestador maestro (usa 'include')

| **Orquestador** | AWS Glue | - |â”œâ”€â”€ deploy-all.sh              # Script de despliegue para Ubuntu/Linux

| **Query Engine** | AWS Athena | - |â”œâ”€â”€ .gitignore                 # Protege .env y archivos sensibles

| **Storage** | AWS S3 | - |â”‚

| **Contenedor** | Docker | - |â”œâ”€â”€ ms-databases/              # 3 bases de datos de prueba

â”‚   â”œâ”€â”€ docker-compose.yml     # MySQL, PostgreSQL, MongoDB

## ğŸŒ API Endpointsâ”‚   â”œâ”€â”€ .env                   # Credenciales de BD (gitignored)

â”‚   â”œâ”€â”€ .env.example           # Plantilla para configurar

### Analytics y Reportesâ”‚   â”œâ”€â”€ init-mysql.sql         # Datos de prueba MS1

â”‚   â”œâ”€â”€ init-postgres.sql      # Datos de prueba MS2

| MÃ©todo | Endpoint | DescripciÃ³n |â”‚   â”œâ”€â”€ init-mongo.js          # Datos de prueba MS3

|--------|----------|-------------|â”‚   â””â”€â”€ README.md              # DocumentaciÃ³n detallada

| `GET` | `/dashboard-ejecutivo` | Dashboard con KPIs principales |â”‚

| `GET` | `/cuentas/por-tipo` | DistribuciÃ³n de cuentas por tipo |â”œâ”€â”€ datalake-ingester/         # ETL: Extrae y sube a S3

| `GET` | `/transacciones/por-mes` | Volumen de transacciones mensuales |â”‚   â”œâ”€â”€ docker-compose.yml     # 3 ingesters (uno por DB)

| `GET` | `/clientes/activos` | Total de clientes activos |â”‚   â”œâ”€â”€ ingester.py            # LÃ³gica de ingesta (boto3)

| `GET` | `/ingresos/mensuales` | Ingresos por mantenimiento de cuentas |â”‚   â”œâ”€â”€ .env                   # AWS credentials + S3 buckets

â”‚   â”œâ”€â”€ .env.example           # Plantilla

### Consultas SQL Personalizadasâ”‚   â”œâ”€â”€ requirements.txt       # boto3, pymysql, psycopg2, pymongo

â”‚   â””â”€â”€ README.md              # DocumentaciÃ³n ETL

| MÃ©todo | Endpoint | DescripciÃ³n |â”‚

|--------|----------|-------------|â””â”€â”€ api-consultas/             # API REST con FastAPI

| `POST` | `/query` | Ejecutar query SQL personalizada en Athena |    â”œâ”€â”€ docker-compose.yml     # Servicio API (puerto 8000)

| `GET` | `/query/{execution_id}` | Obtener resultado de query por ID |    â”œâ”€â”€ main.py                # Endpoints de FastAPI

    â”œâ”€â”€ athena_client.py       # Cliente para consultas Athena

### Utilidades    â”œâ”€â”€ queries.py             # Queries SQL predefinidas

    â”œâ”€â”€ .env                   # AWS credentials + config Athena

| MÃ©todo | Endpoint | DescripciÃ³n |    â”œâ”€â”€ .env.example           # Plantilla

|--------|----------|-------------|    â”œâ”€â”€ requirements.txt       # fastapi, boto3, uvicorn

| `GET` | `/` | InformaciÃ³n del servicio |    â”œâ”€â”€ DataLake_API_Postman_Collection.json  # 16 requests

| `GET` | `/health` | Health check |    â””â”€â”€ README.md              # DocumentaciÃ³n API con endpoints

| `GET` | `/docs` | DocumentaciÃ³n Swagger UI |```



## ğŸ“Š Modelo de Respuesta## ï¿½ Arquitectura de Redes Docker



### Dashboard Ejecutivo### Conectividad Entre Componentes

```json

{```

  "fecha_generacion": "2025-01-15T10:30:00",â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

  "total_clientes": 15234,â”‚          Red: datalake-network                  â”‚

  "clientes_activos": 14892,â”‚          (ComunicaciÃ³n interna)                 â”‚

  "total_cuentas": 28456,â”‚                                                 â”‚

  "saldo_total_sistema": 125000000.50,â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚

  "transacciones_mes_actual": 45678,â”‚  â”‚ MySQL    â”‚  â”‚PostgreSQL â”‚  â”‚ MongoDB  â”‚    â”‚

  "ingresos_mantenimiento": 284560.00,â”‚  â”‚ :3306    â”‚  â”‚  :5432    â”‚  â”‚ :27017   â”‚    â”‚

  "distribucion_cuentas": {â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚

    "Ahorro": 18234,â”‚       â†‘              â†‘              â†‘          â”‚

    "Corriente": 8123,â”‚       â”‚   ConexiÃ³n directa via    â”‚          â”‚

    "Plazo Fijo": 2099â”‚       â”‚   nombres de contenedores  â”‚          â”‚

  }â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚

}â”‚                      â”‚                         â”‚

```â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚

â”‚           â”‚  Ingester Containers â”‚             â”‚

### Transacciones por Mesâ”‚           â”‚  - ingesta01-mysql   â”‚             â”‚

```jsonâ”‚           â”‚  - ingesta02-postgresâ”‚             â”‚

{â”‚           â”‚  - ingesta03-mongodb â”‚             â”‚

  "periodo": "2024-01-01 a 2024-12-31",â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚

  "data": [â”‚                                                 â”‚

    {â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

      "mes": "2024-01",

      "total_transacciones": 3456,        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

      "monto_total": 1250000.00        â”‚  API-Consultas  â”‚  â† NO necesita red Docker

    },        â”‚    :8000        â”‚     (solo se comunica con AWS)

    {        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

      "mes": "2024-02",                â”‚

      "total_transacciones": 3789,                â†“ HTTPS (boto3)

      "monto_total": 1380000.00        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

    }        â”‚  Amazon Athena  â”‚

  ]        â”‚  (AWS Cloud)    â”‚

}        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```                â”‚

                â†“ Query S3

## ğŸ“Š Estructura del Data Lake        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

        â”‚   Amazon S3     â”‚

**S3 Bucket**: `s3://cloud-bank-datalake/`        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

**Estructura de Directorios:**

```### Â¿QuiÃ©n necesita estar en la red Docker?

s3://cloud-bank-datalake/

â”œâ”€â”€ clientes/| Componente | Red Docker | RazÃ³n |

â”‚   â”œâ”€â”€ clientes.parquet|------------|------------|-------|

â”‚   â””â”€â”€ _metadata| **ms-databases** | âœ… `datalake-network` | Crea la red para que otros componentes se conecten |

â”œâ”€â”€ cuentas/| **datalake-ingester** | âœ… `datalake-network` | Necesita conectarse directamente a las 3 bases de datos usando nombres de contenedores (`mysql-db`, `postgres-db`, `mongo-db`) |

â”‚   â”œâ”€â”€ cuentas.parquet| **api-consultas** | âŒ **NO necesita red** | Solo se comunica con Amazon Athena (servicio AWS en la nube). No accede directamente a las bases de datos |

â”‚   â””â”€â”€ _metadata

â””â”€â”€ transacciones/### Flujo de Conexiones

    â”œâ”€â”€ year=2024/

    â”‚   â”œâ”€â”€ month=01/1. **Ingesters â†’ Bases de Datos**: ConexiÃ³n directa dentro de `datalake-network`

    â”‚   â”‚   â””â”€â”€ transacciones.parquet   - Host: `mysql-db`, `postgres-db`, `mongo-db` (nombres de contenedores)

    â”‚   â”œâ”€â”€ month=02/   - ComunicaciÃ³n: TCP interno de Docker

    â”‚   â”‚   â””â”€â”€ transacciones.parquet

    â””â”€â”€ _metadata2. **Ingesters â†’ S3**: ConexiÃ³n HTTPS vÃ­a boto3 SDK

```   - Usa IAM Role del EC2 para autenticaciÃ³n

   - No requiere credenciales hardcoded

**AWS Glue Tables:**

- `cloud_bank_db.clientes`3. **API â†’ Athena/S3**: ConexiÃ³n HTTPS vÃ­a boto3 SDK

- `cloud_bank_db.cuentas`   - Usa IAM Role del EC2 para autenticaciÃ³n

- `cloud_bank_db.transacciones`   - Lee datos desde S3 vÃ­a queries Athena

   - **Nunca accede directamente a las bases de datos**

## â˜ï¸ Servicios AWS Utilizados

### ConfiguraciÃ³n de Red con `include`

- **EC2**: Hospedaje de la API

- **S3**: Almacenamiento del Data Lake (formato Parquet)Cuando se usa `include` en Docker Compose (como en este proyecto):

- **Athena**: Motor de consultas SQL sobre S3

- **Glue**: CatÃ¡logo de datos y crawler1. **El archivo raÃ­z** (`docker-compose.yml`) define la red:

- **IAM**: Permisos para acceso a S3/Athena   ```yaml

- **VPC & Security Groups**: Red y firewall   networks:

     datalake-network:

## ğŸš€ Despliegue RÃ¡pido       driver: bridge

   ```

```bash

# En la instancia EC22. **Los archivos individuales** referencian la red pero **NO la definen**:

cd ~/cloud-bank-service/ms5/api-consultas   ```yaml

   services:

# Configurar AWS credentials y S3 bucket en .env     mysql-db:

# AWS_ACCESS_KEY_ID=AKIA...       networks:

# AWS_SECRET_ACCESS_KEY=...         - datalake-network

# AWS_REGION=us-east-1   

# S3_BUCKET=cloud-bank-datalake   # âŒ NO incluir secciÃ³n "networks:" al final del archivo

   ```

docker-compose up -d

3. **La red se crea automÃ¡ticamente** al ejecutar:

# Verificar   ```bash

curl http://localhost:8000/health   docker-compose up -d

curl http://localhost:8000/docs   ```

```

**Importante**: Los archivos `ms-databases/docker-compose.yml` y `datalake-ingester/docker-compose.yml` solo **referencian** la red en los servicios, pero no la definen al final. Esto evita conflictos con el `include`.

Ver guÃ­a completa: `../DEPLOYMENT_GUIDE.md`

## ï¿½ğŸš€ Inicio RÃ¡pido en EC2 Ubuntu

## ğŸ”— Dependencias

### Pre-requisitos

**Consumido por:**

- Dashboards ejecutivos1. **EC2 Ubuntu 22.04** (t2.medium o superior recomendado)

- Herramientas de BI (Tableau, Power BI, etc.)2. **IAM Role** con permisos S3, Glue y Athena (ej: `LabRole` para AWS Academy)

- Reportes programados3. **3 Buckets S3** creados:

   - `raw-ms1-data-bgc` (para MySQL)

**Consume:**   - `raw-ms2-data-bgc` (para PostgreSQL)

- AWS S3 (Data Lake)   - `raw-ms3-data-bgc` (para MongoDB)

- AWS Athena (Query Engine)4. **Docker y Docker Compose instalados** en EC2

- Datos histÃ³ricos de MS1, MS2, MS4 (a travÃ©s del Data Lake)

### InstalaciÃ³n de Docker en Ubuntu

## ğŸ“– DocumentaciÃ³n Adicional

```bash

- **Swagger UI**: `http://{EC2-IP}:8000/docs`# Actualizar sistema

- **OpenAPI Spec**: `http://{EC2-IP}:8000/openapi.json`sudo apt update && sudo apt upgrade -y

- **Data Lake Setup**: Ver `check_s3_structure.sh`, `check_glue_tables.py`

- **Ingester**: Ver `../datalake-ingester/README.md`# Instalar Docker

- **GuÃ­a de deployment detallada**: Ver `../DEPLOYMENT_GUIDE.md`curl -fsSL https://get.docker.com -o get-docker.sh

sudo sh get-docker.sh

## ğŸ“ Notas

# Agregar usuario al grupo docker (evita usar sudo)

- Las consultas en Athena escanean datos en S3, se cobra por TB escaneadosudo usermod -aG docker $USER

- El formato Parquet optimiza el escaneo (columnar, comprimido)newgrp docker

- Los datos se particionan por aÃ±o/mes para eficiencia

- El Data Ingester corre periÃ³dicamente para actualizar el Data Lake# Verificar instalaciÃ³n

- Athena queries son asÃ­ncronas (se obtiene execution_id para consultar resultado)docker --version

- Se recomienda usar vistas materializadas para dashboards de actualizaciÃ³n frecuentedocker compose version

```

### 1. Clonar el Proyecto y Configurar Variables

```bash
# Clonar repositorio
git clone <tu-repositorio-url>
cd cloud-m5

# Configurar variables de entorno en cada componente
cd ms-databases
cp .env.example .env
nano .env  # Editar credenciales

cd ../datalake-ingester
cp .env.example .env
nano .env  # Configurar AWS credentials y buckets S3

cd ../api-consultas
cp .env.example .env
nano .env  # Configurar AWS credentials y Athena

cd ..  # Volver a raÃ­z
```

**âš ï¸ IMPORTANTE**: Los archivos `.env` contienen credenciales reales y NO se suben a Git.

### 2. Desplegar Todos los Servicios

#### Verificar versiÃ³n de Docker Compose

```bash
# Docker Compose V2 (mÃ¡s reciente - integrado con Docker)
docker compose version

# Docker Compose V1 (versiÃ³n antigua - comando separado)
docker-compose --version
```

**Nota**: Los comandos cambian segÃºn la versiÃ³n:
- **V2**: `docker compose` (con espacio)
- **V1**: `docker-compose` (con guiÃ³n)

En los ejemplos siguientes usaremos **V1** (`docker-compose`), si tienes V2 usa `docker compose`.

#### OpciÃ³n A: Docker Compose desde la RaÃ­z (MÃ¡s Simple)

```bash
# Levanta TODOS los servicios (7 contenedores)
docker compose up -d

# Ver estado
docker compose ps

# Ver logs en tiempo real
docker compose logs -f

# Detener todo
docker compose down
```

#### OpciÃ³n B: Script Bash con Comandos Ãštiles

```bash
# Dar permisos de ejecuciÃ³n
chmod +x deploy-all.sh

# Levantar todos los servicios (con espera de 15s para DBs)
./deploy-all.sh start

# Ver estado de todos los contenedores
./deploy-all.sh status

# Ver logs de todos los servicios
./deploy-all.sh logs

# Detener todos los servicios
./deploy-all.sh stop

# Reiniciar todos los servicios
./deploy-all.sh restart

# Reconstruir contenedores despuÃ©s de cambios
./deploy-all.sh rebuild
```

### 3. Configurar AWS Glue (Desde AWS Console)

```bash
# 1. Crear base de datos en Glue
aws glue create-database --database-input '{"Name": "datalake_db"}'

# 2. Crear y ejecutar 3 crawlers (uno por bucket S3)
# Configurar desde AWS Console:
#   - Crawler 1: raw-ms1-data-bgc â†’ tabla: ms1_*
#   - Crawler 2: raw-ms2-data-bgc â†’ tabla: ms2_*
#   - Crawler 3: raw-ms3-data-bgc â†’ tabla: ms3_*

# 3. Ejecutar crawlers para catalogar datos
# Resultado esperado: 9 tablas en Glue Data Catalog
```

### 4. Verificar Despliegue

```bash
# Ver contenedores corriendo (deberÃ­as ver 7)
docker ps

# Probar bases de datos
docker logs mysql-test-db
docker logs postgres-test-db
docker logs mongo-test-db

# Probar ingesters (deben ejecutarse y terminar)
docker logs ingesta01-mysql
docker logs ingesta02-postgresql
docker logs ingesta03-mongodb

# Probar API REST
curl http://localhost:8000/health
# Respuesta esperada: {"status":"healthy"}

# Ver Swagger UI en navegador
# http://<IP-PUBLICA-EC2>:8000/docs
```

## ï¿½ Servicios Desplegados

| Servicio | Puerto | DescripciÃ³n |
|----------|--------|-------------|
| **mysql-test-db** | 3307 | MySQL 8.0 con datos de MS1 (usuarios, pedidos, productos) |
| **postgres-test-db** | 5433 | PostgreSQL 15 con datos de MS2 (clientes, facturas, pagos) |
| **mongo-test-db** | 27018 | MongoDB 7.0 con datos de MS3 (logs, sesiones, eventos) |
| **ingesta01-mysql** | - | Extrae MySQL â†’ S3 (formato JSON Lines) |
| **ingesta02-postgresql** | - | Extrae PostgreSQL â†’ S3 (formato JSON Lines) |
| **ingesta03-mongodb** | - | Extrae MongoDB â†’ S3 (formato JSON Lines) |
| **api-consultas-datalake** | 8000 | API REST con 15+ endpoints (Athena queries) |

## ğŸŒ API REST - Endpoints Principales

Accede a la documentaciÃ³n interactiva: **`http://<EC2-IP>:8000/docs`**

### Endpoints Disponibles:

- `GET /health` - Health check
- `GET /api/dashboard` - Dashboard general con mÃ©tricas
- `GET /api/usuarios` - Listar usuarios (MS1)
- `GET /api/pedidos` - Listar pedidos (MS1)
- `GET /api/productos` - Listar productos (MS1)
- `GET /api/clientes` - Listar clientes (MS2)
- `GET /api/facturas` - Listar facturas (MS2)
- `GET /api/pagos` - Listar pagos (MS2)
- `GET /api/logs` - Listar logs (MS3)
- `GET /api/sesiones` - Listar sesiones (MS3)
- `GET /api/eventos` - Listar eventos (MS3)
- `GET /api/pedidos/{pedido_id}` - Pedido por ID
- `GET /api/productos-por-categoria/{categoria}` - Productos filtrados
- `GET /api/facturas-por-cliente/{cliente_id}` - Facturas de cliente
- `POST /api/query-custom` - Ejecutar query SQL personalizada

**ğŸ“¥ Importar Postman Collection**: `api-consultas/DataLake_API_Postman_Collection.json` (16 requests listos)

## ğŸ“š DocumentaciÃ³n Detallada por Componente

- **[ms-databases/README.md](./ms-databases/README.md)** - Bases de datos, esquemas, datos de prueba
- **[datalake-ingester/README.md](./datalake-ingester/README.md)** - Ingesters, formato JSON Lines, particiones S3
- **[api-consultas/README.md](./api-consultas/README.md)** - API REST, endpoints, Athena queries, ejemplos

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­a | VersiÃ³n |
|-----------|------------|---------|
| **Cloud** | AWS S3, Glue, Athena, EC2, IAM | - |
| **Lenguaje** | Python | 3.11 |
| **Framework API** | FastAPI | 0.104.1 |
| **SDK AWS** | boto3 | 1.34.0 |
| **Bases de Datos** | MySQL | 8.0 |
| | PostgreSQL | 15 |
| | MongoDB | 7.0 |
| **ContainerizaciÃ³n** | Docker | 24.x |
| | Docker Compose | v3.8 |
| **Formato de Datos** | JSON Lines (NDJSON) | - |

## ğŸ” Seguridad y Buenas PrÃ¡cticas

### Archivos Protegidos (`.gitignore`):
- âœ… `.env` - Credenciales reales
- âœ… `*.pem`, `*.ppk` - Llaves SSH
- âœ… `notes.txt` - Notas personales
- âœ… `mysql-data/`, `postgres-data/`, `mongo-data/` - VolÃºmenes de datos

### Credenciales AWS:
- Usa **IAM Roles** en EC2 (no hardcodear access keys)
- Para AWS Academy usa `LabRole` / `LabInstanceProfile`
- Rota credenciales regularmente

## ï¿½ Publicar ImÃ¡genes en Docker Hub (Opcional)

El proyecto incluye nombres de imÃ¡genes configurados para facilitar la publicaciÃ³n en Docker Hub.

### ImÃ¡genes del Proyecto

| Imagen | Tag | DescripciÃ³n |
|--------|-----|-------------|
| `br4yangc/cloud-computing-project-ms-5` | `ingester-mysql` | Ingester para MySQL â†’ S3 |
| `br4yangc/cloud-computing-project-ms-5` | `ingester-postgresql` | Ingester para PostgreSQL â†’ S3 |
| `br4yangc/cloud-computing-project-ms-5` | `ingester-mongodb` | Ingester para MongoDB â†’ S3 |
| `br4yangc/cloud-computing-project-ms-5` | `api-consultas` | API REST con FastAPI para Athena |

**Nota**: Las bases de datos (MySQL, PostgreSQL, MongoDB) usan imÃ¡genes oficiales pÃºblicas y no requieren publicaciÃ³n.

### Proceso de PublicaciÃ³n

```bash
# 1. Login en Docker Hub (requiere cuenta gratuita en hub.docker.com)
docker login -u br4yangc

# 2. Construir todas las imÃ¡genes (desde la raÃ­z del proyecto)
docker-compose build

# 3. Publicar imÃ¡genes en Docker Hub
docker push br4yangc/cloud-computing-project-ms-5:ingester-mysql
docker push br4yangc/cloud-computing-project-ms-5:ingester-postgresql
docker push br4yangc/cloud-computing-project-ms-5:ingester-mongodb
docker push br4yangc/cloud-computing-project-ms-5:api-consultas

# 4. Verificar en Docker Hub
# https://hub.docker.com/r/br4yangc/cloud-computing-project-ms-5/tags
```

### Ventajas de Publicar

- âœ… **Despliegue rÃ¡pido**: Descarga imÃ¡genes pre-construidas en lugar de construir
- âœ… **Portabilidad**: Deploy en mÃºltiples servidores sin clonar cÃ³digo fuente
- âœ… **Portafolio**: Proyecto visible pÃºblicamente y fÃ¡cil de demostrar
- âœ… **Versionamiento**: Control de versiones con tags (`v1.0`, `v2.0`, etc.)
- âœ… **ColaboraciÃ³n**: Otros pueden probar tu proyecto fÃ¡cilmente

### Usar ImÃ¡genes Publicadas

Una vez publicadas, otros pueden desplegar sin construir:

```bash
# Clonar solo archivos de configuraciÃ³n
git clone <tu-repo-url>
cd cloud-computing-project-ms-5

# Configurar .env en cada carpeta

# Descargar imÃ¡genes pre-construidas
docker-compose pull

# Levantar servicios (sin necesidad de construir)
docker-compose up -d
```

### LÃ­mites del Plan Gratuito

Docker Hub plan gratuito incluye:
- âœ… Repositorios pÃºblicos ilimitados
- âœ… 1 repositorio privado
- âœ… Sin lÃ­mite de pulls autenticados
- âš ï¸ 200 pulls cada 6 horas para usuarios anÃ³nimos

## ï¿½ğŸ”§ Comandos Ãštiles

```bash
# Ver logs de un servicio especÃ­fico
docker logs -f <nombre-contenedor>

# Reiniciar un servicio
docker compose restart <nombre-servicio>

# Reconstruir despuÃ©s de cambios en cÃ³digo
docker compose up -d --build

# Detener y eliminar volÃºmenes (âš ï¸ elimina datos de BD)
docker compose down -v

# Ver uso de recursos
docker stats

# Limpiar contenedores detenidos
docker system prune -a

# Ver redes Docker
docker network ls

# Inspeccionar un contenedor
docker inspect <nombre-contenedor>
```

## ğŸ› Troubleshooting

### Error: "networks.datalake-network conflicts with imported resource"

Este error ocurre cuando mÃºltiples archivos docker-compose intentan definir la misma red.

**SoluciÃ³n**: La red debe definirse **solo en el archivo raÃ­z** (`docker-compose.yml`):

```yaml
# docker-compose.yml (raÃ­z)
networks:
  datalake-network:
    driver: bridge
```

Los archivos individuales (`ms-databases/`, `datalake-ingester/`) **NO** deben tener secciÃ³n `networks:` al final, solo referencian la red en los servicios.

```bash
# Si persiste el error, limpiar y reiniciar:
docker-compose down
docker network prune -f
docker-compose up -d
```

**Nota importante**: Solo los **ingesters** y **bases de datos** necesitan estar en la red `datalake-network`. La **API** no necesita esta red porque solo se comunica con Athena (AWS).

### Error: "Cannot connect to Docker daemon"
```bash
# Verificar que Docker estÃ© corriendo
sudo systemctl status docker

# Iniciar Docker
sudo systemctl start docker

# Agregar usuario al grupo docker
sudo usermod -aG docker $USER
newgrp docker
```

### Error: "The container name is already in use"

Este error ocurre cuando hay contenedores de intentos anteriores que no se eliminaron.

```bash
# Detener todos los servicios
docker-compose down

# Eliminar contenedores especÃ­ficos que quedaron
docker rm -f $(docker ps -aq --filter "name=ingesta") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=mysql-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=postgres-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=mongo-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=api-consultas") 2>/dev/null || true

# Limpiar redes huÃ©rfanas
docker network prune -f

# Levantar servicios limpios
docker-compose up -d
```

### Error: "Port already in use"
```bash
# Ver quÃ© proceso usa el puerto
sudo lsof -i :8000

# O cambiar puerto en .env del servicio
```

### Error: "Permission denied" en S3
- Verifica que el IAM Role en EC2 tenga polÃ­ticas: `AmazonS3FullAccess`, `AWSGlueConsoleFullAccess`, `AmazonAthenaFullAccess`
- Revisa que los buckets existan en la regiÃ³n correcta (us-east-1)
- Verifica credenciales en archivos `.env`

### Athena devuelve errores de tipos de datos
- Verifica que los datos en S3 estÃ©n en **JSON Lines** (no JSON pretty-printed)
- Ejecuta los Glue Crawlers para actualizar el esquema
- Los ingesters ya convierten `Decimal` â†’ `float` y `datetime` â†’ `ISO string`

### Ingesters no suben datos a S3
```bash
# Ver logs de ingesters
docker logs ingesta01-mysql
docker logs ingesta02-postgresql
docker logs ingesta03-mongodb

# Verificar conectividad con AWS
aws s3 ls s3://raw-ms1-data-bgc/

# Revisar .env en datalake-ingester/
```

### Warnings: "AWS_ACCESS_KEY_ID variable is not set"
Estos warnings son **normales y esperados** si usas IAM Role en EC2:
```
WARN[0000] The "AWS_ACCESS_KEY_ID" variable is not set. Defaulting to a blank string.
WARN[0000] The "AWS_SECRET_ACCESS_KEY" variable is not set. Defaulting to a blank string.
WARN[0000] The "AWS_SESSION_TOKEN" variable is not set. Defaulting to a blank string.
```

**Puedes ignorarlos** porque:
- El EC2 usa IAM Role (`LabRole`) para autenticaciÃ³n automÃ¡tica
- No necesitas credenciales hardcoded en los `.env`
- Los servicios obtienen credenciales temporales del EC2 metadata service

Si prefieres eliminar los warnings, deja las variables vacÃ­as en los `.env`:
```bash
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=
```

### API devuelve 500 Internal Server Error
```bash
# Ver logs de la API
docker logs api-consultas-datalake

# Verificar que Glue Data Catalog tenga tablas
aws glue get-tables --database-name datalake_db

# Verificar .env en api-consultas/
```

## ğŸ“ Limitaciones de AWS Academy

- âš ï¸ **No puedes crear IAM Roles nuevos** â†’ Usa `LabRole` existente
- âš ï¸ **Sesiones expiran despuÃ©s de 4 horas** â†’ Re-inicia la lab
- âš ï¸ **Algunos servicios estÃ¡n restringidos** (Lambda, RDS managed, etc.)
- âœ… **S3, Glue, Athena y EC2 funcionan perfectamente**

## ğŸ¤ ContribuciÃ³n

```bash
# 1. Copiar plantillas de variables
cp ms-databases/.env.example ms-databases/.env
cp datalake-ingester/.env.example datalake-ingester/.env
cp api-consultas/.env.example api-consultas/.env

# 2. Configurar credenciales reales (NO subir a Git)

# 3. Hacer cambios en cÃ³digo

# 4. Probar localmente
docker compose up -d --build

# 5. Asegurarse que .env estÃ© en .gitignore

# 6. Commit y push (sin .env)
git add .
git commit -m "descripciÃ³n"
git push
```

## ğŸ“„ Licencia

Proyecto educativo para AWS Academy - Cloud Computing.

---

**Desarrollado con â˜ï¸ para aprender arquitecturas DataLake en AWS**
